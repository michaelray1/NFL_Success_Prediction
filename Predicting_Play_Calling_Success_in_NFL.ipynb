{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Play Calling Success in the NFL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I train various machine learning models to predict the success of a \"run\" or \"pass\" play call in the NFL. The notebook is accompanied by another Jupyter Notebook where I clean the NFL data for easy use by these algorithms. See that notebook if you want to know more about the original dataset and how to clean data using the Pandas library.\n",
    "\n",
    "Before I begin my analysis, I find it appropriate to present my opinion on how analytics should be used in sports. While I think that analytics has a incredibly high use potential in sports, I do see its limitations. Analytics recommendations should always be taken with the knowledge of what assumptions the recommendation is making, the limitations of the recommendation system, and the knowledge that probabilities are just probabilities, not certainties. With that out of the way, let's dive into the analysis of this data set.\n",
    "\n",
    "This notebook presents the prediction accuracy of four different machine learning algorithms as applied to the NFL Play-by-Play data set found here (https://www.kaggle.com/datasets/toddsteussie/nfl-play-statistics-dataset-2004-to-present). Three of the algorithms I use are tree-based machine learning algorithms (random forest with 2 different representations of the data and one boosted tree algorithm) and one of them is a neural network.\n",
    "\n",
    "My goal with this algorithm is to be able to recommend whether an offensive coordinator should call a rushing or passing play based on statistical analysis of past data. What my algorithm does is use pre-snap data to predict whether a rushing or passing play will be a \"success\", \"failure\", or \"neutral\". The definition of what a success is is found below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rules For Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are a description of the rules used by the add_success function to evaluate whether each play was a success or not. I chose these rules based on what I feel should be considered a successful football play. The rules are different depending on what down it is. In the data set, successes are represented by 1, failures by -1, and neutral plays by 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any down:\n",
    "   - if you get a first down or score, that's a success\n",
    "\n",
    "First down: \n",
    "   - success = gaining (3/10) or greater of yards to the sticks\n",
    "   - neutral = between 1 yard and (3/10) of yards to the sticks\n",
    "   - fail = 0 yards or negative yards\n",
    "   \n",
    "Second down:\n",
    "   - success = gaining (1/2) or greater of yards to the sticks\n",
    "   - neutral = between 1 yard and (1/2) of yards to the sticks\n",
    "   - fail = 0 or negative yards\n",
    "   \n",
    "Third down:\n",
    "   - success = first down\n",
    "   - neutral = nothing\n",
    "   - fail = not first down\n",
    "   \n",
    "Fourth down:\n",
    "   - success = first down\n",
    "   - neutral = nothing\n",
    "   - fail = not first down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find it useful to present the results of the analysis first before presenting the analysis itself.\n",
    "\n",
    "In my opinion, the best metric to decide which algorithm is \"best\" in this context, is the algorithms recall precentage for successful plays. This is the percentage of times that my algorithm predicts a successful play, where the play is, in fact, successful. In other words, if my algorithm predicts you will have a successful play-call, then I have a 57% chance of being right. This may sound low, but just consider the following fact: less than 49% of total play calls end up in a success. We can reasonably assume that every play call made by an offensive coordinator/head coach is predicted to be a success, therefore my best algorithm beats the average head coach by roughly 8%!!\n",
    "\n",
    "A table summarizing each of the algorithms results is show below. Remember that (at least in my opinion) the precision on successful plays is the most important metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with unnormalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    failed play       0.54      0.48      0.51     78361\n",
      "   neutral play       0.44      0.20      0.28     26532\n",
      "successful play       0.55      0.67      0.61    102256\n",
      "\n",
      "       accuracy                           0.54    207149\n",
      "      macro avg       0.51      0.45      0.46    207149\n",
      "   weighted avg       0.53      0.54      0.53    207149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skl.metrics.classification_report(y_test, preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with noramlized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    failed play       0.55      0.45      0.50     78361\n",
      "   neutral play       0.42      0.24      0.31     26532\n",
      "successful play       0.55      0.69      0.62    102256\n",
      "\n",
      "       accuracy                           0.54    207149\n",
      "      macro avg       0.51      0.46      0.47    207149\n",
      "   weighted avg       0.54      0.54      0.53    207149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skl.metrics.classification_report(y_trans_test, preds_trans, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    failed play       0.53      0.52      0.53     78361\n",
      "   neutral play       0.38      0.34      0.36     26532\n",
      "successful play       0.58      0.61      0.60    102256\n",
      "\n",
      "       accuracy                           0.54    207149\n",
      "      macro avg       0.50      0.49      0.49    207149\n",
      "   weighted avg       0.54      0.54      0.54    207149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skl.metrics.classification_report(y_test, xgb_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    failed play       0.62      0.39      0.48     78361\n",
      "   neutral play       0.50      0.24      0.33     26532\n",
      "successful play       0.56      0.80      0.66    102256\n",
      "\n",
      "       accuracy                           0.57    207149\n",
      "      macro avg       0.56      0.48      0.49    207149\n",
      "   weighted avg       0.58      0.57      0.55    207149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skl.metrics.classification_report(y_test, preds_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presented below is the full code used to train each of the algorithms on our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as skl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Michaelray/Documents/NFL_project/archive (3)\n"
     ]
    }
   ],
   "source": [
    "cd archive\\ (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "md = pd.read_csv('model_data.csv')\n",
    "md = md.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = md.drop(columns=['success']), md['success']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with unnormalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    failed play       0.54      0.48      0.51     78361\n",
      "   neutral play       0.44      0.20      0.28     26532\n",
      "successful play       0.55      0.67      0.61    102256\n",
      "\n",
      "       accuracy                           0.54    207149\n",
      "      macro avg       0.51      0.45      0.46    207149\n",
      "   weighted avg       0.53      0.54      0.53    207149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['failed play', 'neutral play', 'successful play']\n",
    "preds = rf.predict(X_test)\n",
    "print(skl.metrics.classification_report(y_test, preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['playId', 'gameId', 'playSequence', 'quarter', 'playNumberByTeam',\n",
    "                'gameClock', 'down', 'distance', 'distanceToGoalPre', 'evPre', \n",
    "              'homeScorePre', 'visitingScorePre', 'huddle', \n",
    "              \n",
    "              'Bears home', 'Bengals home', 'Bills home', \n",
    "              'Broncos home', 'Browns home', 'Buccaneers home', 'Cardinals home', 'Chargers home', \n",
    "              'Chiefs home', 'Colts home', 'Cowboys home', 'Dolphins home', 'Eagles home', \n",
    "              'Falcons home', 'Giants home', 'Jaguars home', 'Jets home', 'Lions home', \n",
    "              'Niners home', 'Packers home', 'Panthers home', 'Patriots home', 'Raiders home', \n",
    "              'Rams home', 'Ravens home', 'Saints home', 'Seahawks home', 'Steelers home', 'Texans home', \n",
    "              'Titans home', 'Vikings home', 'Washington home', 'Bears away', 'Bengals away', 'Bills away', \n",
    "              'Broncos away', 'Browns away', 'Buccaneers away', 'Cardinals away', 'Chargers away', \n",
    "              'Chiefs away', 'Colts away', 'Cowboys away', 'Dolphins away', 'Eagles away', 'Falcons away', \n",
    "              'Giants away', 'Jaguars away', 'Jets away', 'Lions away', 'Niners away', 'Packers away', \n",
    "              'Panthers away', 'Patriots away', 'Raiders away', 'Rams away', 'Ravens away', 'Saints away', \n",
    "              'Seahawks away', 'Steelers away', 'Texans away', 'Titans away', 'Vikings away', 'Washington away',\n",
    "              \n",
    "              \n",
    "                'homeTeamPossession', 'pass', 'rush', 'success']\n",
    "\n",
    "normalizables = ['playId', 'gameId', 'playSequence', 'quarter', 'playNumberByTeam',\n",
    "                'gameClock', 'down', 'distance', 'distanceToGoalPre', 'evPre', \n",
    "              'homeScorePre', 'visitingScorePre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize all numerical variables\n",
    "scaler = StandardScaler()\n",
    "ct = make_column_transformer((scaler, normalizables), remainder='passthrough')\n",
    "md_trans = ct.fit_transform(md)\n",
    "md_trans = pd.DataFrame(md_trans, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make new test, train data\n",
    "X_trans, y_trans = md_trans.drop(columns=['success']), md_trans['success']\n",
    "X_trans_train, X_trans_test, y_trans_train, y_trans_test = train_test_split(X_trans, y_trans, test_size=0.33, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "rf2 = RandomForestClassifier()\n",
    "rf2.fit(X_trans_train, y_trans_train)\n",
    "preds_trans = rf2.predict(X_trans_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    failed play       0.55      0.45      0.50     78361\n",
      "   neutral play       0.42      0.24      0.31     26532\n",
      "successful play       0.55      0.69      0.62    102256\n",
      "\n",
      "       accuracy                           0.54    207149\n",
      "      macro avg       0.51      0.46      0.47    207149\n",
      "   weighted avg       0.54      0.54      0.53    207149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skl.metrics.classification_report(y_trans_test, preds_trans, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Higher lambda and higher gamma makes a more conservative tree\n",
    "#Higher max_deptch means more likelihood of overfitting\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=3\n",
    ")\n",
    "xgb_classifier.fit(X_trans_train, y_train_nn)\n",
    "xgb_preds = np.argmax(xgb_classifier.predict(X_trans_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    failed play       0.53      0.52      0.53     78361\n",
      "   neutral play       0.38      0.34      0.36     26532\n",
      "successful play       0.58      0.61      0.60    102256\n",
      "\n",
      "       accuracy                           0.54    207149\n",
      "      macro avg       0.50      0.49      0.49    207149\n",
      "   weighted avg       0.54      0.54      0.54    207149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['failed play', 'neutral play', 'successful play']\n",
    "print(skl.metrics.classification_report(y_test, xgb_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To use loss function in NN, we need to one-hot encode the target variables\n",
    "y_train_nn = pd.get_dummies(y_train)\n",
    "#y_train_nn = y_train_nn.rename(columns = {-1 : 'failedPlay', 0 : 'neutralPlay', 1 : 'successfulPlay'})\n",
    "y_test_nn = pd.get_dummies(y_test)\n",
    "#y_test_nn = y_test_nn.rename(columns = {-1 : 'failedPlay', 0 : 'neutralPlay', 1 : 'successfulPlay'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform target data from -1, 0, 1 to 0, 1, 2\n",
    "X, y = md.drop(columns=['success']), md['success']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "y_train.loc[y_train==1] = 2\n",
    "y_train.loc[y_train==0] = 1\n",
    "y_train.loc[y_train==(-1)] = 0\n",
    "y_test.loc[y_test==1] = 2\n",
    "y_test.loc[y_test==0] = 1\n",
    "y_test.loc[y_test==(-1)] = 0\n",
    "\n",
    "y_train_nn = pd.get_dummies(y_train)\n",
    "y_test_nn = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Michaelray/opt/anaconda3/envs/local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 16:04:11.840075: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.InputLayer(input_shape = (X_train.shape[1], )))\n",
    "model.add(tf.keras.layers.Dense(18, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(9, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_trans_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    failed play       0.62      0.39      0.48     78361\n",
      "   neutral play       0.50      0.24      0.33     26532\n",
      "successful play       0.56      0.80      0.66    102256\n",
      "\n",
      "       accuracy                           0.57    207149\n",
      "      macro avg       0.56      0.48      0.49    207149\n",
      "   weighted avg       0.58      0.57      0.55    207149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_nn = np.argmax(model.predict(X_trans_test), axis=1)\n",
    "target_names = ['failed play', 'neutral play', 'successful play']\n",
    "print(skl.metrics.classification_report(y_test, preds_nn, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
